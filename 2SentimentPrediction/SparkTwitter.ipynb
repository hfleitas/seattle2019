{
    "metadata": {
        "kernelspec": {
            "name": "sparkkernel",
            "display_name": "Spark | Scala"
        },
        "language_info": {
            "name": "scala",
            "mimetype": "text/x-scala",
            "codemirror_mode": "text/x-scala",
            "pygments_lexer": "scala"
        }
    },
    "nbformat_minor": 2,
    "nbformat": 4,
    "cells": [
        {
            "cell_type": "markdown",
            "source": [
                "<p align=\"center\">\r\n",
                "<img src =\"https://raw.githubusercontent.com/microsoft/azuredatastudio/master/src/sql/media/microsoft_logo_gray.svg?sanitize=true\" width=\"250\" align=\"center\">\r\n",
                "</p>\r\n",
                "\r\n",
                "# **Twitter Streaming with SQL Server & Spark**\r\n",
                "\r\n",
                "In this notebook, we will go through the process of using Spark to stream tweets from the Twitter API, and then stream the resulting data into the SQL Server data pool. Once the data is in the data pool, we will perform queries on it using T-SQL or the Spark-SQL connector. \r\n",
                "\r\n",
                "## **Steps**\r\n",
                "1. [Create a Twitter Developer Account](https://developer.twitter.com/en/apply-for-access.html).\r\n",
                "2. Setup\r\n",
                "    1. Create 'TwitterData' database.\r\n",
                "    2. Create an External Data Source 'TweetsDataSource'.\r\n",
                "    3. Create an External Table 'Tweets'.\r\n",
                "    4. Change kernel from \"SQL\" to \"Spark | Scala\".\r\n",
                "    5. Import packages.\r\n",
                "    6. Enter required parameters.\r\n",
                "3. Define and create a TwitterStream object.\r\n",
                "4. Start the TwitterStream.\r\n",
                "5. Validate streaming data.\r\n",
                "6. Stream data into SQL Server data pool.\r\n",
                "7. Query the data from the data pool external table using T-SQL or the Spark-SQL connector.\r\n",
                "8. Stop the TwitterStream"
            ],
            "metadata": {
                "azdata_cell_guid": "edf821ac-d627-4d6e-8c7c-7ee918f072f3"
            }
        },
        {
            "cell_type": "markdown",
            "source": [
                "## **1. Create a Twitter Developer Account**\n",
                "[Create a Twitter Developer Account](https://developer.twitter.com/en/apply-for-access.html) and enter the credentials in the Setup section below. These credentials will be used to authenticate the application with Twitter and allow you to stream data from the platform."
            ],
            "metadata": {
                "azdata_cell_guid": "d3a9df62-793b-4415-9574-4edfccb205ba"
            }
        },
        {
            "cell_type": "markdown",
            "source": [
                "## **2. Setup**\n",
                "1. Create a database in the SQL Server master instance named 'TwitterData'.\n",
                "2. Create an External Data Source to the Data Pool named 'TweetsDataSource'.\n",
                "3. Create an External Table in the Data Pool named 'Tweets'.\n",
                "4. Change the Kernel from \"SQL\" to \"Spark | Scala\".\n",
                "5. Import Java packages.\n",
                "6. Specify setup parameters"
            ],
            "metadata": {
                "azdata_cell_guid": "514963d4-c9eb-42a7-bd81-c6735f79d647"
            }
        },
        {
            "cell_type": "markdown",
            "source": [
                "### **2.1 Create TwitterData Database and Retrieve Hostname**"
            ],
            "metadata": {
                "azdata_cell_guid": "196dd8cd-e4d7-45c7-b6f8-21dde6c75ae7"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "USE master\n",
                "IF EXISTS(select * from sys.databases where name='TwitterData')\n",
                "DROP DATABASE TwitterData;\n",
                "GO\n",
                "CREATE DATABASE TwitterData;\n",
                "GO\n",
                "USE TwitterData;\n",
                "GO"
            ],
            "metadata": {
                "azdata_cell_guid": "abf4ebf4-c8fc-4316-a300-2c64bd8f4592"
            },
            "outputs": [
                {
                    "output_type": "display_data",
                    "data": {
                        "text/html": "Commands completed successfully."
                    },
                    "metadata": {}
                },
                {
                    "output_type": "display_data",
                    "data": {
                        "text/html": "Commands completed successfully."
                    },
                    "metadata": {}
                },
                {
                    "output_type": "display_data",
                    "data": {
                        "text/html": "Commands completed successfully."
                    },
                    "metadata": {}
                },
                {
                    "output_type": "display_data",
                    "data": {
                        "text/html": "Total execution time: 00:00:01.419"
                    },
                    "metadata": {}
                }
            ],
            "execution_count": 1
        },
        {
            "cell_type": "markdown",
            "source": [
                "Use the following cell to check your server name. If it returns ```master-0```, your hostname will be ```master-0.master-svc```. You will define this value in the Parameters section."
            ],
            "metadata": {
                "azdata_cell_guid": "02e6cd9a-ef88-419c-afa0-e6a666f1070e"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "SELECT @@Servername;"
            ],
            "metadata": {
                "azdata_cell_guid": "0827942d-a223-4ba8-8168-2fb57a4a2488"
            },
            "outputs": [
                {
                    "output_type": "display_data",
                    "data": {
                        "text/html": "(1 row affected)"
                    },
                    "metadata": {}
                },
                {
                    "output_type": "display_data",
                    "data": {
                        "text/html": "Total execution time: 00:00:00.091"
                    },
                    "metadata": {}
                },
                {
                    "output_type": "execute_result",
                    "metadata": {},
                    "execution_count": 2,
                    "data": {
                        "application/vnd.dataresource+json": {
                            "schema": {
                                "fields": [
                                    {
                                        "name": "(No column name)"
                                    }
                                ]
                            },
                            "data": [
                                {
                                    "0": "master-0"
                                }
                            ]
                        },
                        "text/html": "<table><tr><th>(No column name)</th></tr><tr><td>master-0</td></tr></table>"
                    }
                }
            ],
            "execution_count": 2
        },
        {
            "cell_type": "markdown",
            "source": [
                "### **2.2 Create External Data Source 'TweetsDataSource'**"
            ],
            "metadata": {
                "azdata_cell_guid": "03542af4-1e39-4049-a982-a44fce4cebd4"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "USE TwitterData\n",
                "GO\n",
                "\n",
                "IF NOT EXISTS(SELECT * FROM sys.external_data_sources WHERE name = 'TweetsDataSource')\n",
                "  CREATE EXTERNAL DATA SOURCE TweetsDataSource\n",
                "  WITH (LOCATION = 'sqldatapool://controller-svc/default');"
            ],
            "metadata": {
                "azdata_cell_guid": "b01e9faf-d701-4a5e-95a3-7afb66b1249b",
                "tags": []
            },
            "outputs": [
                {
                    "output_type": "display_data",
                    "data": {
                        "text/html": "Commands completed successfully."
                    },
                    "metadata": {}
                },
                {
                    "output_type": "display_data",
                    "data": {
                        "text/html": "Commands completed successfully."
                    },
                    "metadata": {}
                },
                {
                    "output_type": "display_data",
                    "data": {
                        "text/html": "Total execution time: 00:00:00.033"
                    },
                    "metadata": {}
                }
            ],
            "execution_count": 3
        },
        {
            "cell_type": "markdown",
            "source": [
                "### **2.3 Create External Table 'Tweets'**"
            ],
            "metadata": {
                "azdata_cell_guid": "a2576ce9-bd62-4138-937c-f5ccdfe0834e"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "IF NOT EXISTS(SELECT * FROM sys.external_tables WHERE name = 'Tweets')\n",
                "   CREATE EXTERNAL TABLE [Tweets]\n",
                "   (\"screen_name\" NVARCHAR(MAX), \"createdAt\" DATETIME , \"num_followers\" BIGINT, \"text\" NVARCHAR(MAX))\n",
                "   WITH\n",
                "   (\n",
                "      DATA_SOURCE = TweetsDataSource,\n",
                "      DISTRIBUTION = ROUND_ROBIN\n",
                "   );"
            ],
            "metadata": {
                "azdata_cell_guid": "e80447c6-92a8-459f-aa17-517b89bd5fed"
            },
            "outputs": [
                {
                    "output_type": "display_data",
                    "data": {
                        "text/html": "Commands completed successfully."
                    },
                    "metadata": {}
                },
                {
                    "output_type": "display_data",
                    "data": {
                        "text/html": "Total execution time: 00:00:07.946"
                    },
                    "metadata": {}
                }
            ],
            "execution_count": 4
        },
        {
            "cell_type": "code",
            "source": [
                "USE TwitterData\r\n",
                "CREATE LOGIN user2  WITH PASSWORD ='password123!#' \r\n",
                "CREATE USER user2 FROM LOGIN user2\r\n",
                "ALTER ROLE [db_datareader] ADD MEMBER user2\r\n",
                "ALTER ROLE [db_datawriter] ADD MEMBER user2\r\n",
                "\r\n",
                "EXECUTE( 'Use TwitterData; CREATE LOGIN user2 WITH PASSWORD = ''password123!#'';' )  AT  DATA_SOURCE TweetsDataSource\r\n",
                "EXECUTE( 'Use TwitterData; CREATE USER user2; ALTER ROLE [db_datareader] ADD MEMBER user2; ALTER ROLE [db_datawriter] ADD MEMBER user2;')  AT  DATA_SOURCE TweetsDataSource;"
            ],
            "metadata": {
                "azdata_cell_guid": "a747bd7c-f1b8-496f-9709-ffc8e116d48b"
            },
            "outputs": [
                {
                    "output_type": "display_data",
                    "data": {
                        "text/html": "Commands completed successfully."
                    },
                    "metadata": {}
                },
                {
                    "output_type": "display_data",
                    "data": {
                        "text/html": "Total execution time: 00:00:01.941"
                    },
                    "metadata": {}
                }
            ],
            "execution_count": 5
        },
        {
            "cell_type": "markdown",
            "source": [
                "### **2.4 Change the kernel from \"SQL\" to \"Spark | Scala\"**\n",
                "At the top of the editor, click the Kernel dropdown menu and change the kernel from \"SQL\" to \"Spark | Scala\". This will update the notebook language, and allow you to proceed with the next steps."
            ],
            "metadata": {
                "azdata_cell_guid": "9cf2a253-f6eb-4125-8938-12254ded05a7"
            }
        },
        {
            "cell_type": "markdown",
            "source": [
                "### **2.5 Import packages**"
            ],
            "metadata": {
                "azdata_cell_guid": "04406211-4b11-4be8-b0da-e8ade7e6bdfc"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "import java.io.{BufferedReader, File, FileNotFoundException, InputStream, InputStreamReader}\r\n",
                "import java.net.URLEncoder\r\n",
                "import java.nio.charset.StandardCharsets\r\n",
                "import java.util.Base64\r\n",
                "import javax.crypto.Mac\r\n",
                "import javax.crypto.spec.SecretKeySpec\r\n",
                "import scala.collection.JavaConverters._\r\n",
                "import org.apache.commons.io.IOUtils\r\n",
                "import org.apache.http.client.methods.HttpGet\r\n",
                "import org.apache.http.impl.client.CloseableHttpClient\r\n",
                "import org.apache.http.impl.client.HttpClients\r\n",
                "import org.apache.hadoop.conf.Configuration\r\n",
                "import org.apache.hadoop.fs.FileSystem\r\n",
                "import org.apache.hadoop.fs.Path\r\n",
                "import java.io.PrintWriter\r\n",
                "import org.apache.spark.sql.{SparkSession, SaveMode, Row, DataFrame}"
            ],
            "metadata": {
                "azdata_cell_guid": "fb2fbadd-c710-4a47-a494-2ecc5db0f375"
            },
            "outputs": [
                {
                    "name": "stdout",
                    "text": "Starting Spark application\n",
                    "output_type": "stream"
                },
                {
                    "data": {
                        "text/plain": "<IPython.core.display.HTML object>",
                        "text/html": "<table>\n<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>Current session?</th></tr><tr><td>0</td><td>application_1573196576510_0001</td><td>spark</td><td>idle</td><td><a target=\"_blank\" href=\"https://51.143.103.88:30443/gateway/default/yarn/proxy/application_1573196576510_0001/\">Link</a></td><td><a target=\"_blank\" href=\"https://51.143.103.88:30443/gateway/default/yarn/container/container_1573196576510_0001_01_000001/root\">Link</a></td><td>✔</td></tr></table>"
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/plain": "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…",
                        "application/vnd.jupyter.widget-view+json": {
                            "version_major": 2,
                            "version_minor": 0,
                            "model_id": "b39e12fef1e54b33b99e6863e933c37c"
                        }
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "text": "SparkSession available as 'spark'.\n",
                    "output_type": "stream"
                },
                {
                    "data": {
                        "text/plain": "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…",
                        "application/vnd.jupyter.widget-view+json": {
                            "version_major": 2,
                            "version_minor": 0,
                            "model_id": "ea69dc4372c445eba7a8b82a782362b4"
                        }
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "text": "import java.io.{BufferedReader, File, FileNotFoundException, InputStream, InputStreamReader}\nimport java.net.URLEncoder\nimport java.nio.charset.StandardCharsets\nimport java.util.Base64\nimport javax.crypto.Mac\nimport javax.crypto.spec.SecretKeySpec\nimport scala.collection.JavaConverters._\nimport org.apache.commons.io.IOUtils\nimport org.apache.http.client.methods.HttpGet\nimport org.apache.http.impl.client.CloseableHttpClient\nimport org.apache.http.impl.client.HttpClients\nimport org.apache.hadoop.conf.Configuration\nimport org.apache.hadoop.fs.FileSystem\nimport org.apache.hadoop.fs.Path\nimport java.io.PrintWriter\nimport org.apache.spark.sql.{SparkSession, SaveMode, Row, DataFrame}\n",
                    "output_type": "stream"
                }
            ],
            "execution_count": 3
        },
        {
            "cell_type": "markdown",
            "source": [
                "### **2.6 Parameters**\r\n",
                "Enter the required parameters for the Spark streaming job to connect to SQL Server.\r\n",
                "\r\n",
                "In this example, the connection is made from Spark to the SQL Server master instance using the internal DNS name (Ex: master-0.master-svc) and port (1433).  Alternatively, and especially if you are using a highly available Always On Availability Group, you can connect to the Kubernetes service that exposes the primary node of the Always On Availability Group.\r\n",
                "\r\n",
                "####  Parameters needed to create Twitter stream\r\n",
                "- Twitter API authentication keys\r\n",
                "\r\n",
                "#### Parameters needed for Spark-SQL connector:\r\n",
                "- user\r\n",
                "- password\r\n",
                "\r\n",
                "#### Optional parameters:\r\n",
                "- hostname\r\n",
                "- port \r\n",
                "- CSV schema\r\n",
                "- Source directory location\r\n",
                "- Set path in hdfs to store tweets\r\n",
                "- Set saving interval for file creation \r\n",
                "- Set Twitter filters\r\n",
                ""
            ],
            "metadata": {
                "azdata_cell_guid": "73fad3ec-a900-4398-a710-990f2c30e0f3"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "// Twitter app autnentication keys\r\n",
                "val consumerKey = \"x4KcSXlFkJ80IgOQPeafaxwqY\"\r\n",
                "val consumerSecret = \"G4w1gkTPIVlNtEZ6MxtPE9VOn42EARWdyugdt4oCo172RjaXVK\"\r\n",
                "val accessToken = \"69367137-v2w0nDtf6uQN9LE10E4iyUBZSoeg6JE830ynnqp34\"\r\n",
                "val accessTokenSecret = \"tcrwhnq7EsL5vl1Ws0RKdpUi39HFZA0ud7Ufosni6sVlE\"\r\n",
                "\r\n",
                "// Provide username/password to SQL Server master instance\r\n",
                "val user = \"user2\"\r\n",
                "val password = \"password123!#\"\r\n",
                "\r\n",
                "// Spark-SQL connector parameters\r\n",
                "val hostname = \"master-0.master-svc\"\r\n",
                "val port = 1433\r\n",
                "val database = \"TwitterData\"\r\n",
                "val url = s\"jdbc:sqlserver://${hostname}:${port};database=${database};user=${user};password=${password};\"\r\n",
                "val dbtable = \"Tweets\"\r\n",
                "val datasource_name = \"TweetsDataSource\"\r\n",
                "\r\n",
                "// Twitter stream object parameters\r\n",
                "val filters = Array(\"PASSSummit\", \"Seattle\", \"SQLServer\", \"Azure\", \"hiramfleitas\", \"Microsoft\", \"Spark\")\r\n",
                "val path = \"/user/twitter/\"\r\n",
                "val savingInterval = 2000"
            ],
            "metadata": {
                "azdata_cell_guid": "3eaece45-6db5-4eab-816c-bdadfffe26ee"
            },
            "outputs": [
                {
                    "data": {
                        "text/plain": "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…",
                        "application/vnd.jupyter.widget-view+json": {
                            "version_major": 2,
                            "version_minor": 0,
                            "model_id": "e7330dbc5ae943538e5144a979ed85da"
                        }
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "text": "consumerKey: String = x4KcSXlFkJ80IgOQPeafaxwqY\nconsumerSecret: String = G4w1gkTPIVlNtEZ6MxtPE9VOn42EARWdyugdt4oCo172RjaXVK\naccessToken: String = 69367137-v2w0nDtf6uQN9LE10E4iyUBZSoeg6JE830ynnqp34\naccessTokenSecret: String = tcrwhnq7EsL5vl1Ws0RKdpUi39HFZA0ud7Ufosni6sVlE\nuser: String = user2\npassword: String = password123!#\nhostname: String = master-0.master-svc\nport: Int = 1433\ndatabase: String = TwitterData\nurl: String = jdbc:sqlserver://master-0.master-svc:1433;database=TwitterData;user=user2;password=password123!#;\ndbtable: String = Tweets\ndatasource_name: String = TweetsDataSource\nfilters: Array[String] = Array(PASSSummit, Seattle, SQLServer, Azure, hiramfleitas, Microsoft, Spark)\npath: String = /user/twitter/\nsavingInterval: Int = 2000\n",
                    "output_type": "stream"
                }
            ],
            "execution_count": 5
        },
        {
            "cell_type": "markdown",
            "source": [
                "## **3. Define and Create TwitterStream object**"
            ],
            "metadata": {
                "azdata_cell_guid": "3bbc4717-16d7-42ad-9fc7-f999edc00734"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "class TwitterStream(\r\n",
                "  consumerKey: String,\r\n",
                "  consumerSecret: String,\r\n",
                "  accessToken: String,\r\n",
                "  accessTokenSecret: String,\r\n",
                "  path: String,\r\n",
                "  savingInterval: Long,\r\n",
                "  filters: Array[String]) {\r\n",
                "  \r\n",
                "  private val threadName = \"tweet-downloader\"\r\n",
                "  \r\n",
                "  {\r\n",
                "    val hasActiveStream = Thread.getAllStackTraces().keySet().asScala.map(_.getName).contains(threadName)\r\n",
                "    if (hasActiveStream) {\r\n",
                "      throw new RuntimeException(\r\n",
                "        \"There is already an active stream that writes tweets to the configured path. \" +\r\n",
                "        \"Please stop the existing stream first (using twitterStream.stop()).\")\r\n",
                "    }\r\n",
                "  }\r\n",
                "  \r\n",
                "  @volatile private var thread: Thread = null\r\n",
                "  @volatile private var isStopped = false\r\n",
                "  @volatile var isDownloading = false\r\n",
                "  @volatile var exception: Throwable = null\r\n",
                "\r\n",
                "  private var httpclient: CloseableHttpClient = null\r\n",
                "  private var input: InputStream = null\r\n",
                "  private var httpGet: HttpGet = null\r\n",
                "  \r\n",
                "  private def encode(string: String): String = {\r\n",
                "    URLEncoder.encode(string, StandardCharsets.UTF_8.name)\r\n",
                "  }\r\n",
                "\r\n",
                "  def start(): Unit = synchronized {\r\n",
                "    isDownloading = false\r\n",
                "    isStopped = false\r\n",
                "    thread = new Thread(threadName) {\r\n",
                "      override def run(): Unit = {\r\n",
                "        httpclient = HttpClients.createDefault()\r\n",
                "        try {\r\n",
                "          requestStream(httpclient)\r\n",
                "        } catch {\r\n",
                "          case e: Throwable => exception = e\r\n",
                "        } finally {\r\n",
                "          //TwitterStream.this.stop()\r\n",
                "        }\r\n",
                "      }\r\n",
                "    }\r\n",
                "    thread.start()\r\n",
                "  }\r\n",
                "\r\n",
                "  private def requestStream(httpclient: CloseableHttpClient): Unit = {\r\n",
                "    val url = \"https://stream.twitter.com/1.1/statuses/filter.json\"\r\n",
                "    val timestamp = System.currentTimeMillis / 1000\r\n",
                "    val nonce = timestamp + scala.util.Random.nextInt\r\n",
                "    val oauthNonce = nonce.toString\r\n",
                "    val oauthTimestamp = timestamp.toString\r\n",
                "\r\n",
                "    val oauthHeaderParams = List(\r\n",
                "      \"oauth_consumer_key\" -> encode(consumerKey),\r\n",
                "      \"oauth_signature_method\" -> encode(\"HMAC-SHA1\"),\r\n",
                "      \"oauth_timestamp\" -> encode(oauthTimestamp),\r\n",
                "      \"oauth_nonce\" -> encode(oauthNonce),\r\n",
                "      \"oauth_token\" -> encode(accessToken),\r\n",
                "      \"oauth_version\" -> \"1.0\"\r\n",
                "    )\r\n",
                "    val requestParams = List(\r\n",
                "      \"track\" -> encode(filters.mkString(\",\"))\r\n",
                "    )\r\n",
                "\r\n",
                "    val parameters = (oauthHeaderParams ++ requestParams).sortBy(_._1).map(pair => s\"\"\"${pair._1}=${pair._2}\"\"\").mkString(\"&\")\r\n",
                "    val base = s\"GET&${encode(url)}&${encode(parameters)}\"\r\n",
                "    val oauthBaseString: String = base.toString\r\n",
                "    val signature = generateSignature(oauthBaseString)\r\n",
                "    val oauthFinalHeaderParams = oauthHeaderParams ::: List(\"oauth_signature\" -> encode(signature))\r\n",
                "    val authHeader = \"OAuth \" + ((oauthFinalHeaderParams.sortBy(_._1).map(pair => s\"\"\"${pair._1}=\"${pair._2}\"\"\"\")).mkString(\", \"))\r\n",
                "\r\n",
                "    httpGet = new HttpGet(s\"https://stream.twitter.com/1.1/statuses/filter.json?${requestParams.map(pair => s\"\"\"${pair._1}=${pair._2}\"\"\").mkString(\"&\")}\")\r\n",
                "    httpGet.addHeader(\"Authorization\", authHeader)\r\n",
                "    println(\"Downloading tweets!\")\r\n",
                "    val response = httpclient.execute(httpGet)\r\n",
                "    val entity = response.getEntity()\r\n",
                "    input = entity.getContent()\r\n",
                "    if (response.getStatusLine.getStatusCode != 200) {\r\n",
                "      throw new RuntimeException(IOUtils.toString(input, StandardCharsets.UTF_8))\r\n",
                "    }\r\n",
                "    isDownloading = true\r\n",
                "    val reader = new BufferedReader(new InputStreamReader(input, StandardCharsets.UTF_8))\r\n",
                "    var line: String = null\r\n",
                "    var lineno = 1\r\n",
                "    line = reader.readLine()\r\n",
                "    var lastSavingTime = System.currentTimeMillis()\r\n",
                "    val s = new StringBuilder()\r\n",
                "   \r\n",
                "    val conf = new Configuration()\r\n",
                "    val fs= FileSystem.get(conf)\r\n",
                "                                                                      \r\n",
                "    while (line != null && !isStopped) {\r\n",
                "      lineno += 1\r\n",
                "      line = reader.readLine()\r\n",
                "      s.append(line + \"\\n\")\r\n",
                "      val now = System.currentTimeMillis()\r\n",
                "      if (now - lastSavingTime >= savingInterval) {\r\n",
                "          \r\n",
                "         val df = spark.read.json(spark.sparkContext.parallelize(Seq(s.toString)))\r\n",
                "         df.write.json(path + now.toString)\r\n",
                "          \r\n",
                "        lastSavingTime = now\r\n",
                "        s.clear()\r\n",
                "      }\r\n",
                "    }\r\n",
                "  }\r\n",
                "\r\n",
                "  private def generateSignature(data: String): String = {\r\n",
                "    val mac = Mac.getInstance(\"HmacSHA1\")\r\n",
                "    val oauthSignature = encode(consumerSecret) + \"&\" + encode(accessTokenSecret)\r\n",
                "    val spec = new SecretKeySpec(oauthSignature.getBytes, \"HmacSHA1\")\r\n",
                "    mac.init(spec)\r\n",
                "    val byteHMAC = mac.doFinal(data.getBytes)\r\n",
                "    return Base64.getEncoder.encodeToString(byteHMAC)\r\n",
                "  }\r\n",
                "\r\n",
                "  def stop(): Unit = synchronized {\r\n",
                "    isStopped = true\r\n",
                "    isDownloading = false\r\n",
                "    try {\r\n",
                "      if (httpGet != null) {\r\n",
                "        httpGet.abort()\r\n",
                "        httpGet = null\r\n",
                "      }\r\n",
                "      if (input != null) {\r\n",
                "        input.close()\r\n",
                "        input = null\r\n",
                "      }\r\n",
                "      if (httpclient != null) {\r\n",
                "        httpclient.close()\r\n",
                "        httpclient = null\r\n",
                "      }\r\n",
                "      if (thread != null) {\r\n",
                "        thread.interrupt()\r\n",
                "        thread = null\r\n",
                "      }\r\n",
                "    } catch {\r\n",
                "      case _: Throwable =>\r\n",
                "    }\r\n",
                "  }\r\n",
                "}\r\n",
                "println(\"class defined\")"
            ],
            "metadata": {
                "azdata_cell_guid": "aa9b5a2d-4f00-4cb9-8e97-7e5d1bcf78ad",
                "tags": [
                    "hide_input"
                ]
            },
            "outputs": [
                {
                    "data": {
                        "text/plain": "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…",
                        "application/vnd.jupyter.widget-view+json": {
                            "version_major": 2,
                            "version_minor": 0,
                            "model_id": "2b1183b81ce144b897504ad89466440d"
                        }
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "text": "warning: there was one deprecation warning; re-run with -deprecation for details\ndefined class TwitterStream\nclass defined\n",
                    "output_type": "stream"
                }
            ],
            "execution_count": 6
        },
        {
            "cell_type": "code",
            "source": [
                "val twitterStream = new TwitterStream(consumerKey, consumerSecret, accessToken, accessTokenSecret, path, savingInterval, filters)"
            ],
            "metadata": {
                "azdata_cell_guid": "b109f960-9fc3-4dbd-869f-996bcae6c294"
            },
            "outputs": [
                {
                    "data": {
                        "text/plain": "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…",
                        "application/vnd.jupyter.widget-view+json": {
                            "version_major": 2,
                            "version_minor": 0,
                            "model_id": "701e59d012284acc9567bd99abc85310"
                        }
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "text": "twitterStream: TwitterStream = TwitterStream@4e084713\n",
                    "output_type": "stream"
                }
            ],
            "execution_count": 7
        },
        {
            "cell_type": "markdown",
            "source": [
                "## **4. Start TwitterStream**"
            ],
            "metadata": {
                "azdata_cell_guid": "12f79299-4ce3-4154-8175-0acf2735f068"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "twitterStream.start()\r\n",
                "\r\n",
                "if (twitterStream.exception != null) { throw twitterStream.exception }"
            ],
            "metadata": {
                "azdata_cell_guid": "f846a370-c9be-499e-8d96-a769e0ffd862"
            },
            "outputs": [
                {
                    "data": {
                        "text/plain": "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…",
                        "application/vnd.jupyter.widget-view+json": {
                            "version_major": 2,
                            "version_minor": 0,
                            "model_id": "d093332f95dc49d38351fd21f465d735"
                        }
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "text": "Downloading tweets!\n",
                    "output_type": "stream"
                }
            ],
            "execution_count": 8
        },
        {
            "cell_type": "markdown",
            "source": [
                "## **5. Validate streaming data**\r\n",
                "\r\n",
                "Refresh the /user/twitter directory in HDFS and you should see some directories containing data files with the Tweet data."
            ],
            "metadata": {
                "azdata_cell_guid": "ffb3e9d0-0dfc-4060-bb5b-4520958dd890"
            }
        },
        {
            "cell_type": "markdown",
            "source": [
                "## **6. Stream data into SQL Server data pool**\r\n",
                "\r\n",
                "Now, we can start another job to stream the incoming data into the SQL Server data pool. We will first create the Tweet Dataframe, and then write the data from the dataframe to an external table over the data pool using the Spark-SQL connector."
            ],
            "metadata": {
                "azdata_cell_guid": "0ffd027f-95e4-4718-b806-d4acebbe4874"
            }
        },
        {
            "cell_type": "markdown",
            "source": [
                "### **Create Tweet Dataframe**"
            ],
            "metadata": {
                "azdata_cell_guid": "500644d5-d1a2-4a78-96d1-e58fa87e1881"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "val tweets = spark.read.json(path + \"*\")\r\n",
                "val tweets_schema = tweets.schema\r\n",
                "\r\n",
                "val tweetStream = spark.readStream.\r\n",
                "|schema(tweets_schema).\r\n",
                "|json(path + \"*\").\r\n",
                "|filter($\"lang\" === \"en\").\r\n",
                "|withColumn(\"screen_name\", $\"user.screen_name\").\r\n",
                "|withColumn(\"num_followers\", $\"user.followers_count\").\r\n",
                "|withColumn(\"createdAt\", from_utc_timestamp(from_unixtime(unix_timestamp($\"created_at\", \"EEE MMM dd HH:mm:ss ZZZZ yyyy\")),\"EST\")).\r\n",
                "|select(\"screen_name\",\"createdAt\",\"num_followers\", \"text\") "
            ],
            "metadata": {
                "azdata_cell_guid": "d30d7aad-b449-440c-8211-15d73ac8b10a"
            },
            "outputs": [
                {
                    "data": {
                        "text/plain": "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…",
                        "application/vnd.jupyter.widget-view+json": {
                            "version_major": 2,
                            "version_minor": 0,
                            "model_id": "646917f688ce4902bad4c1a2ce4b7a0d"
                        }
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "text": "tweets: org.apache.spark.sql.DataFrame = [created_at: string, display_text_range: array<bigint> ... 25 more fields]\ntweets_schema: org.apache.spark.sql.types.StructType = StructType(StructField(created_at,StringType,true), StructField(display_text_range,ArrayType(LongType,true),true), StructField(entities,StructType(StructField(hashtags,ArrayType(StructType(StructField(indices,ArrayType(LongType,true),true), StructField(text,StringType,true)),true),true), StructField(media,ArrayType(StructType(StructField(additional_media_info,StructType(StructField(monetizable,BooleanType,true)),true), StructField(display_url,StringType,true), StructField(expanded_url,StringType,true), StructField(id,LongType,true), StructField(id_str,StringType,true), StructField(indices,ArrayType(LongType,true),true), StructField(media_url,StringType,true), StructField(media_url_https,StringType,true), StructField(sizes,StructType...tweetStream: org.apache.spark.sql.DataFrame = [screen_name: string, createdAt: timestamp ... 2 more fields]\n",
                    "output_type": "stream"
                }
            ],
            "execution_count": 9
        },
        {
            "cell_type": "markdown",
            "source": [
                "### **Write data to an external table using the Spark-SQL Connector**"
            ],
            "metadata": {
                "azdata_cell_guid": "b4f3476f-ae35-420c-96cd-cf0a9f131c46"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "val query = tweetStream.writeStream.outputMode(\"append\").foreachBatch{ (batchDF: DataFrame, batchId: Long) => \r\n",
                "                batchDF.write\r\n",
                "                    .format(\"com.microsoft.sqlserver.jdbc.spark\")\r\n",
                "                    .mode(\"append\")\r\n",
                "                    .option(\"url\", url)\r\n",
                "                    .option(\"dbtable\", dbtable)\r\n",
                "                    .option(\"user\", user)\r\n",
                "                    .option(\"password\", password)\r\n",
                "                    .option(\"dataPoolDataSource\",datasource_name).save()\r\n",
                "               }.start()\r\n",
                "query.processAllAvailable()\r\n",
                "//query.awaitTermination(40000)"
            ],
            "metadata": {
                "azdata_cell_guid": "eb0690d9-7705-408b-906f-314dc9456242"
            },
            "outputs": [
                {
                    "data": {
                        "text/plain": "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…",
                        "application/vnd.jupyter.widget-view+json": {
                            "version_major": 2,
                            "version_minor": 0,
                            "model_id": "60146d0ef4104f9687762041760a730f"
                        }
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "text": "query: org.apache.spark.sql.streaming.StreamingQuery = org.apache.spark.sql.execution.streaming.StreamingQueryWrapper@2de0c122\n",
                    "output_type": "stream"
                }
            ],
            "execution_count": 10
        },
        {
            "cell_type": "markdown",
            "source": [
                "## **7. Query the data from the data pool external table using T-SQL or the Spark-SQL connector**\r\n",
                "Now, you are streaming data from the source HDFS directory to the data pool table. An external table has been created in the targeted database specified above. You can view the table in the explorer tree and query it using T-SQL. \r\n",
                "\r\n",
                "If you want to view the current count of records in the external table, use the code below that uses the Spark-SQL connector to query data from SQL Server into a data frame.\r\n",
                "\r\n",
                "You can continue to add files to the /user/twitter directory to see that the Spark-SQL connector automatically picks up new records and adds them to the data pool table."
            ],
            "metadata": {
                "azdata_cell_guid": "b00a4b24-fab5-4315-bae5-965b2beba881"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "def df_read(dbtable: String,\r\n",
                "                url: String,\r\n",
                "                dataPoolDataSource: String=\"\"): DataFrame = {\r\n",
                "                spark.read\r\n",
                "                        .format(\"com.microsoft.sqlserver.jdbc.spark\")\r\n",
                "                        .option(\"url\", url)\r\n",
                "                        .option(\"dbtable\", dbtable)\r\n",
                "                        .option(\"user\", user)\r\n",
                "                        .option(\"password\", password)\r\n",
                "                        .option(\"dataPoolDataSource\", datasource_name)\r\n",
                "                        .load()\r\n",
                "                }"
            ],
            "metadata": {
                "azdata_cell_guid": "b083528c-8e6b-4c77-8b96-b60d043cbcbd"
            },
            "outputs": [
                {
                    "data": {
                        "text/plain": "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…",
                        "application/vnd.jupyter.widget-view+json": {
                            "version_major": 2,
                            "version_minor": 0,
                            "model_id": "fcf769eb027545c29f66e72826723602"
                        }
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "text": "df_read: (dbtable: String, url: String, dataPoolDataSource: String)org.apache.spark.sql.DataFrame\n",
                    "output_type": "stream"
                }
            ],
            "execution_count": 11
        },
        {
            "cell_type": "code",
            "source": [
                "val new_df = df_read(dbtable, url, dataPoolDataSource=datasource_name)\r\n",
                "new_df.count\r\n",
                "new_df.limit(10).show"
            ],
            "metadata": {
                "azdata_cell_guid": "5f400a06-9b84-4885-b0e3-ecfdd63f8938",
                "tags": []
            },
            "outputs": [
                {
                    "data": {
                        "text/plain": "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…",
                        "application/vnd.jupyter.widget-view+json": {
                            "version_major": 2,
                            "version_minor": 0,
                            "model_id": "b86c2fa4814a442598d9f164fbd68148"
                        }
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "text": "new_df: org.apache.spark.sql.DataFrame = [screen_name: string, createdAt: timestamp ... 2 more fields]\nres29: Long = 66\n+---------------+-------------------+-------------+--------------------+\n|    screen_name|          createdAt|num_followers|                text|\n+---------------+-------------------+-------------+--------------------+\n|nemarampunavat1|2019-11-08 02:43:28|            6|Microsoft office ...|\n|          Diagg|2019-11-08 02:43:38|          732|RT @ITguySoCal: G...|\n|    SMAGlendale|2019-11-08 02:43:24|           60|The latest The Gl...|\n|     _meldelmar|2019-11-08 02:43:03|           36|RT @cjsewall9: Wh...|\n|    4thgenitboy|2019-11-08 02:44:27|        10859|yeah you guys jus...|\n|     David_GISI|2019-11-08 02:44:25|          173|RT @cjsewall9: Wh...|\n|       jamflora|2019-11-08 02:43:01|          450|What baffled me t...|\n| smallwordpress|2019-11-08 02:43:35|          453|RT @verge: Micros...|\n| InsiderPeacock|2019-11-08 02:43:42|           11|Show me dem TD?s ...|\n|  Harsha_Streak|2019-11-08 02:44:05|          381|RT @3one4Capital:...|\n+---------------+-------------------+-------------+--------------------+\n\n",
                    "output_type": "stream"
                }
            ],
            "execution_count": 16
        },
        {
            "cell_type": "markdown",
            "source": [
                "## **8. Stop the TwitterStream**"
            ],
            "metadata": {
                "azdata_cell_guid": "3d0bbecf-38e0-4883-84a3-107cfd556522"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "twitterStream.stop()"
            ],
            "metadata": {
                "azdata_cell_guid": "7e995a68-2da1-4a52-8bd6-7ef04d9c8f49"
            },
            "outputs": [
                {
                    "data": {
                        "text/plain": "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…",
                        "application/vnd.jupyter.widget-view+json": {
                            "version_major": 2,
                            "version_minor": 0,
                            "model_id": "fae3da304d604036a648a4be2f20422c"
                        }
                    },
                    "metadata": {},
                    "output_type": "display_data"
                }
            ],
            "execution_count": 15
        }
    ]
}